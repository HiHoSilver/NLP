{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6973e9-6fb1-4fe2-be7c-71890d255821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def identify_topics_with_lda(abstract, num_topics=3, num_words=3):\n",
    "    # Tokenize and preprocess the abstract into pseudo-documents\n",
    "    sentences = sent_tokenize(abstract)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    tokenized_docs = []\n",
    "    for sentence in sentences:\n",
    "        tokens = word_tokenize(sentence.lower())\n",
    "        cleaned_tokens = [word for word in tokens if word not in stop_words and word not in string.punctuation]\n",
    "        tokenized_docs.append(cleaned_tokens)\n",
    "    \n",
    "    # Create bigram and trigram models\n",
    "    bigram = Phrases(tokenized_docs, min_count=2, threshold=10)  # Adjust `min_count` and `threshold` as needed\n",
    "    trigram = Phrases(bigram[tokenized_docs], threshold=10)\n",
    "    bigram_phraser = Phraser(bigram)\n",
    "    trigram_phraser = Phraser(trigram)\n",
    "    \n",
    "    # Apply the bigram and trigram models to tokens\n",
    "    tokenized_docs_with_phrases = [trigram_phraser[bigram_phraser[doc]] for doc in tokenized_docs]\n",
    "    \n",
    "    # Prepare the data for LDA\n",
    "    dictionary = Dictionary(tokenized_docs_with_phrases)\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs_with_phrases]\n",
    "    \n",
    "    # Train LDA model\n",
    "    lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=10)\n",
    "    \n",
    "    # Extract the topics\n",
    "    topics = lda_model.print_topics(num_topics=num_topics, num_words=num_words)\n",
    "    \n",
    "    # Plot topic distribution\n",
    "    plot_topic_distribution(lda_model, corpus, num_topics)\n",
    "    \n",
    "    return topics\n",
    "\n",
    "def plot_topic_distribution(lda_model, corpus, num_topics):\n",
    "    \"\"\"\n",
    "    Plots a bar chart showing topic distribution with meaningful labels.\n",
    "    \"\"\"\n",
    "    # Aggregate topic weights across all pseudo-documents\n",
    "    topic_weights = [0] * num_topics\n",
    "    for doc_topics in lda_model[corpus]:\n",
    "        for topic_id, weight in doc_topics:\n",
    "            topic_weights[topic_id] += weight\n",
    "    \n",
    "    # Normalize topic weights for visibility\n",
    "    total_weight = sum(topic_weights)\n",
    "    topic_weights = [weight / total_weight for weight in topic_weights]\n",
    "    \n",
    "    # Create topic labels using top keywords\n",
    "    topic_labels = []\n",
    "    for topic_id in range(num_topics):\n",
    "        keywords = lda_model.show_topic(topic_id, topn=3)\n",
    "        label = \", \".join([word for word, weight in keywords])\n",
    "        topic_labels.append(f\"Topic {topic_id + 1}: {label}\")\n",
    "    \n",
    "    # Plot the bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(topic_labels, topic_weights, color='skyblue', alpha=0.7)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.xlabel('Topics')\n",
    "    plt.ylabel('Normalized Weight')\n",
    "    plt.title('Topic Distribution Across Abstract')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Execute processing\n",
    "abstract = input(\"Enter an abstract to generate topics: \")\n",
    "topics = identify_topics_with_lda(abstract)\n",
    "for idx, topic in topics:\n",
    "    print(f\"Topic {idx + 1}: {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7067c24-d11b-470a-8802-d5b7c620a37d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
